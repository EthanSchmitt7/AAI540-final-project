{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4416a85",
   "metadata": {},
   "source": [
    "# Endpoint Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d54143a-6ab1-403d-9056-c8c1c4759bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029ae980-f04f-42c9-918a-7935d035d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to S3 and deploy endpoint\n",
    "s3 = boto3.client(\"s3\")\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "bucket_name = sess.default_bucket()\n",
    "model_path = \"airdata/model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4050086-0090-4642-9269-5cb1995fefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# Define model artifact file name\n",
    "tar_model_path = \"model.tar.gz\"\n",
    "\n",
    "# Create a tar.gz file containing the model.pt\n",
    "with tarfile.open(tar_model_path, \"w:gz\") as tar:\n",
    "    tar.add(\"best_model_03.pt\", arcname=\"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66e426b-4678-4523-a615-7c09ef26ab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uploaded to: s3://sagemaker-us-east-1-768099485759/airdata/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Upload model file\n",
    "s3.upload_file(tar_model_path, bucket_name, \"airdata/model.tar.gz\")\n",
    "s3_model_uri = f\"s3://{bucket_name}/airdata/model.tar.gz\"\n",
    "\n",
    "print(\"Model uploaded to:\", s3_model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c897b3-acb3-4a65-863b-32b49803408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and deploy SageMaker model\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_uri,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"code\",\n",
    "    framework_version=\"1.12\",\n",
    "    py_version=\"py38\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663a5f5f-4d3d-439c-9d83-65d0e8ad21dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!\n",
      "SageMaker endpoint deployed at: pytorch-inference-2025-02-19-17-18-00-634\n"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(instance_type=\"ml.m5.large\", initial_instance_count=1)\n",
    "\n",
    "print(\"\\nSageMaker endpoint deployed at:\", predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23f5b16-17f3-44df-977a-6f12b4cef46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the deployed endpoint for testing\n",
    "runtime_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc836da-ce85-4f31-bc47-cb4e17efce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_endpoint(endpoint_name, input_data):\n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps({\"data\": input_data}),\n",
    "    )\n",
    "    result = json.loads(response[\"Body\"].read().decode())\n",
    "    print(\"Prediction response:\", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e7a73",
   "metadata": {},
   "source": [
    "## Load in production data to simulate queries to the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load production data from the .npz file\n",
    "production_data = np.load(\"production_data.npz\")\n",
    "prod_X = production_data[\"X\"]  # Extracting the input data (features)\n",
    "prod_y = production_data[\"y\"]  # Extracting the labels (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f8c46",
   "metadata": {},
   "source": [
    "## Simulate Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ab181c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sleep\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m----> 4\u001b[0m     query_endpoint(predictor\u001b[38;5;241m.\u001b[39mendpoint_name, [row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m      5\u001b[0m     sleep(pd\u001b[38;5;241m.\u001b[39mto_timedelta(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mseconds)\n",
      "File \u001b[1;32m<stringsource>:69\u001b[0m, in \u001b[0;36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1470\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._line_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1512\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1313\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1950\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ethan\\school\\MSAAI\\AAI 540\\final-project\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ethan\\school\\MSAAI\\AAI 540\\final-project\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Simulate feeding data every 60 seconds\n",
    "for i in range(len(prod_X)):\n",
    "    # Get the current batch (you may want to adjust this to send larger batches)\n",
    "    current_batch = prod_X[i : i + 1]  # Send one sample at a time (or increase if batch is needed)\n",
    "\n",
    "    # Send data to the endpoint for inference\n",
    "    result = query_endpoint(current_batch)\n",
    "\n",
    "    # Sleep for 60 seconds before sending the next batch\n",
    "    sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
